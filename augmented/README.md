> *augmented* RNNs

* Notes:

    - Notable augmentation of RNNs:
        - Neural Turing Machines. Have external memory that they can read and write to.
        - Attentional Interfaces. Allow RNNs to focus on parts of their input.
        - Adaptive Computation Time. Allows for varying amounts of computation per step.
        - Neural Programmers. Can call functions, building programs as they run.

    - Neural Training Machines. Combine a RNN with an external memory bank, which is an array of vectors.
        <img src="assets/rnn_memory.svg" style="display:block;margin-left:auto; margin-right:auto; width:75%">
        
        -  Every step NTMs, read and write everywhere, just to differnet extents.


---
* References:

    - [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)
